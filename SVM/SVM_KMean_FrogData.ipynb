{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "1. a\n",
    "'''\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, Markdown\n",
    "data_raw = pd.read_csv('Frogs_MFCCs.csv', sep=\",\", header=0)\n",
    "data = data_raw.iloc[:,:25]\n",
    "msk = np.random.rand(len(data)) < 0.7\n",
    "train_data = data[msk]\n",
    "np_train_data_features = train_data.iloc[:,:22].values\n",
    "test_data = data[~msk]\n",
    "np_test_data_features = test_data.iloc[:,:22].values\n",
    "label_columns = [\"Family\",\"Genus\",\"Species\"]\n",
    "np_train_data_targets = {}\n",
    "np_test_data_targets = {}\n",
    "for i in range(3):\n",
    "    temp_np_train_target = train_data.iloc[:,22+i:22+i+1].values.ravel()\n",
    "    temp_np_test_target = test_data.iloc[:,22+i:22+i+1].values.ravel()\n",
    "    np_train_data_targets[label_columns[i]] = temp_np_train_target\n",
    "    np_test_data_targets[label_columns[i]] = temp_np_test_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters are {'C': 1.0, 'gamma': 1.4} with a score of 0.75\n",
      "The best parameters are {'C': 10.0, 'gamma': 0.1} with a score of 0.71\n",
      "The best parameters are {'C': 10.0, 'gamma': 0.1} with a score of 0.69\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "1. b(i), (ii)\n",
    "'''\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "PENALTY_PRAMA_POINTS = 7\n",
    "SIGMA_PRAMA_POINTS = 20\n",
    "svm = SVC()\n",
    "kf = KFold(n_splits=10)\n",
    "C_range = np.logspace(0, 6, PENALTY_PRAMA_POINTS)\n",
    "gamma_range = np.linspace(0.1, 2.0, SIGMA_PRAMA_POINTS)\n",
    "param_grid = dict(C=C_range, gamma=gamma_range)\n",
    "best_Cs = [] \n",
    "best_Sigmas = []\n",
    "for label in label_columns:\n",
    "    gridCV = GridSearchCV(estimator=svm, param_grid=param_grid,scoring='accuracy',cv=kf)\n",
    "\n",
    "    gridCV.fit(np_train_data_features, np_train_data_targets[label])\n",
    "    print(\"The best parameters for label %s are %s with a accuracy of %0.2f\"\n",
    "      % (label, gridCV.best_params_, gridCV.best_score_))\n",
    "    best_Cs.append(gridCV.best_params_['C'])\n",
    "    best_Sigmas.append(gridCV.best_params_['gamma'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy for label Family is 0.9895\n",
      "Test accuracy for label Genus is 0.9748\n",
      "Test accuracy for label Species is 0.9789\n",
      "Exact match rate is 0.9702\n",
      "hamming loss rate is 0.0190\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "1. b (ii) coni.\n",
    "The best parameters are {'C': 1.0, 'gamma': 1.4} with a score of 0.75\n",
    "The best parameters are {'C': 10.0, 'gamma': 0.1} with a score of 0.71\n",
    "The best parameters are {'C': 10.0, 'gamma': 0.1} with a score of 0.69\n",
    "'''\n",
    "from sklearn.metrics import hamming_loss\n",
    "# best_Cs = [1, 10, 10]\n",
    "# best_Sigmas = [1.4, 0.1, 0.1]\n",
    "test_pred_labels = []\n",
    "for i in range(len(label_columns)):\n",
    "    label = label_columns[i]\n",
    "    best_C = best_Cs[i]\n",
    "    best_Sigma = best_Sigmas[i]\n",
    "    svm = SVC(C=best_C, gamma = best_Sigma)\n",
    "    svm.fit(np_train_data_features, np_train_data_targets[label])\n",
    "    temp_score = svm.score(np_test_data_features, np_test_data_targets[label])\n",
    "    test_pred_labels.append(svm.predict(np_test_data_features))\n",
    "    print(\"Test accuracy for label %s is %0.4f\" % (label, temp_score))\n",
    "\n",
    "test_sample_count = len(test_pred_labels[0])\n",
    "false_count = 0\n",
    "for i in range(test_sample_count):\n",
    "    all_true = True \n",
    "    for j in range(len(label_columns)):\n",
    "        label = label_columns[j]\n",
    "        if(test_pred_labels[j][i] != np_test_data_targets[label][i]):\n",
    "            all_true = False\n",
    "    if not all_true:\n",
    "        false_count += 1\n",
    "temp_test_targets = []\n",
    "for label in label_columns:\n",
    "    temp_test_targets.append (np_test_data_targets[label])\n",
    "hamming_loss_rate = np.sum(np.not_equal(np.transpose(temp_test_targets),\n",
    "                        np.transpose(test_pred_labels)))/float(np.transpose(temp_test_targets).size)\n",
    "print (\"Exact match rate is %0.4f\" % ((test_sample_count-false_count)/test_sample_count))\n",
    "print(\"hamming loss rate is %0.4f\" % (hamming_loss_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters are {'C': 100.0} with a score of 0.74\n",
      "The best parameters are {'C': 0.1} with a score of 0.69\n",
      "The best parameters are {'C': 1000000.0} with a score of 0.67\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "1 b (iii)\n",
    "'''\n",
    "import warnings\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=Warning)\n",
    "PENALTY_PRAMA_POINTS = 10\n",
    "C_range = np.logspace(-3, 6, PENALTY_PRAMA_POINTS)\n",
    "linearSVC = LinearSVC(penalty='l1', dual=False, tol=1e-3, max_iter = 100)\n",
    "kf = KFold(n_splits=10)\n",
    "param_grid = dict(C=C_range)\n",
    "best_Cs = []\n",
    "for label in label_columns:\n",
    "    gridCV = GridSearchCV(estimator=linearSVC, param_grid=param_grid, scoring='accuracy',cv=kf)\n",
    "    gridCV.fit(np_train_data_features, np_train_data_targets[label])\n",
    "    print(\"The best parameters for label %s are %s with a score of %0.2f\"\n",
    "      % (label, gridCV.best_params_, gridCV.best_score_))\n",
    "    best_Cs.append(gridCV.best_params_['C'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy for label Family is 0.9390\n",
      "Test accuracy for label Genus is 0.9276\n",
      "Test accuracy for label Species is 0.9601\n",
      "Exact match rate is 0.9019\n",
      "hamming loss rate is 0.0578\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "1 b (iii)\n",
    "The best parameters are {'C': 100.0} with a score of 0.74\n",
    "The best parameters are {'C': 0.1} with a score of 0.69\n",
    "The best parameters are {'C': 1000000.0} with a score of 0.67\n",
    "'''\n",
    "#best_Cs = [100, 0.1, 1000000]\n",
    "test_pred_labels = []\n",
    "for i in range(len(label_columns)):\n",
    "    label = label_columns[i]\n",
    "    best_C = best_Cs[i]\n",
    "    linearSvm = LinearSVC(penalty='l1', dual=False, tol=1e-3, max_iter = 100, C=best_C)\n",
    "    linearSvm.fit(np_train_data_features, np_train_data_targets[label])\n",
    "    temp_score = linearSvm.score(np_test_data_features, np_test_data_targets[label])\n",
    "    test_pred_labels.append(linearSvm.predict(np_test_data_features))\n",
    "    print(\"Test accuracy for label %s is %0.4f\" % (label, temp_score))\n",
    "\n",
    "test_sample_count = len(test_pred_labels[0])\n",
    "false_count = 0\n",
    "for i in range(test_sample_count):\n",
    "    all_true = True \n",
    "    for j in range(len(label_columns)):\n",
    "        label = label_columns[j]\n",
    "        if(test_pred_labels[j][i] != np_test_data_targets[label][i]):\n",
    "            all_true = False\n",
    "    if not all_true:\n",
    "        false_count += 1\n",
    "temp_test_targets = []\n",
    "for label in label_columns:\n",
    "    temp_test_targets.append (np_test_data_targets[label])\n",
    "hamming_loss_rate = np.sum(np.not_equal(np.transpose(temp_test_targets),\n",
    "                        np.transpose(test_pred_labels)))/float(np.transpose(temp_test_targets).size)\n",
    "print (\"Exact match rate is %0.4f\" % ((test_sample_count-false_count)/test_sample_count))\n",
    "print(\"hamming loss rate is %0.4f\" % (hamming_loss_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "1 b (iv)\n",
    "'''\n",
    "from sklearn.utils import resample\n",
    "species_frequencies = []\n",
    "species_data = []\n",
    "for species, data_species in data.groupby('Species'):\n",
    "    species_data.append (data_species)\n",
    "    species_frequencies.append(data_species.shape[0])\n",
    "median_species_frequency = int(np.median(species_frequencies))\n",
    "mean_species_frequency = int(np.mean(species_frequencies))\n",
    "balanced_species_data = []\n",
    "#Class balancing \n",
    "#upsampling rare species class by and downsampling frequent frequent species by factor of 2 \n",
    "for i in range(len(species_data)):\n",
    "     \n",
    "    n_samples = int(2*species_data[i].shape[0]) if species_data[i].shape[0] < mean_species_frequency else int(2*species_data[i].shape[0])\n",
    "    species_data_resampled = resample(species_data[i], replace=True, \n",
    "                                      n_samples=n_samples, random_state=1)\n",
    "    balanced_species_data.append(species_data_resampled)\n",
    "\n",
    "balanced_species_data = pd.concat(balanced_species_data)\n",
    "\n",
    "\n",
    "msk = np.random.rand(len(balanced_species_data)) < 0.7\n",
    "balanced_train_data = balanced_species_data[msk]\n",
    "# for species, data_species in balanced_train_data.groupby('Genus'):\n",
    "#     print(data_species.shape[0])\n",
    "  \n",
    "np_balanced_train_data_features = balanced_train_data.iloc[:,:22].values\n",
    "balanced_test_data = balanced_species_data[~msk]\n",
    "np_balanced_test_data_features = balanced_test_data.iloc[:,:22].values\n",
    "\n",
    "np_balanced_train_data_targets = {}\n",
    "np_balanced_test_data_targets = {}\n",
    "for i in range(3):\n",
    "    temp_np_train_target = balanced_train_data.iloc[:,22+i:22+i+1].values.ravel()\n",
    "    temp_np_test_target = balanced_test_data.iloc[:,22+i:22+i+1].values.ravel()\n",
    "    np_balanced_train_data_targets[label_columns[i]] = temp_np_train_target\n",
    "    np_balanced_test_data_targets[label_columns[i]] = temp_np_test_target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters are {'C': 10000.0} with a score of 0.79\n",
      "The best parameters are {'C': 100.0} with a score of 0.75\n",
      "The best parameters are {'C': 1000.0} with a score of 0.75\n",
      "Test accuracy for label Family is 0.9366\n",
      "Test accuracy for label Genus is 0.9463\n",
      "Test accuracy for label Species is 0.9593\n",
      "Exact match rate is 0.9156\n",
      "hamming loss rate is 0.0526\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "1 b (iv) conti\n",
    "'''\n",
    "PENALTY_PRAMA_POINTS = 10\n",
    "C_range = np.logspace(-3, 6, PENALTY_PRAMA_POINTS)\n",
    "linearSVC = LinearSVC(penalty='l1', dual=False, tol=1e-3, max_iter = 100)\n",
    "kf = KFold(n_splits=10)\n",
    "param_grid = dict(C=C_range)\n",
    "best_Cs = []\n",
    "for label in label_columns:\n",
    "    gridCV = GridSearchCV(estimator=linearSVC, param_grid=param_grid, scoring='accuracy',cv=kf)\n",
    "    gridCV.fit(np_balanced_train_data_features, np_balanced_train_data_targets[label])\n",
    "    print(\"The best parameters for label %s are %s with a score of %0.2f\"\n",
    "      % (label, gridCV.best_params_, gridCV.best_score_))\n",
    "    best_Cs.append(gridCV.best_params_[\"C\"])\n",
    "\n",
    "test_pred_labels = []\n",
    "for i in range(len(label_columns)):\n",
    "    label = label_columns[i]\n",
    "    best_C = best_Cs[i]\n",
    "    linearSvm = LinearSVC(penalty='l1', dual=False, tol=1e-3, max_iter = 100, C=best_C)\n",
    "    linearSvm.fit(np_balanced_train_data_features, np_balanced_train_data_targets[label])\n",
    "    temp_score = linearSvm.score(np_balanced_test_data_features, np_balanced_test_data_targets[label])\n",
    "    test_pred_labels.append(linearSvm.predict(np_balanced_test_data_features))\n",
    "    print(\"Test accuracy for label %s is %0.4f\" % (label, temp_score))\n",
    "\n",
    "test_sample_count = len(test_pred_labels[0])\n",
    "false_count = 0\n",
    "for i in range(test_sample_count):\n",
    "    all_true = True \n",
    "    for j in range(len(label_columns)):\n",
    "        label = label_columns[j]\n",
    "        if(test_pred_labels[j][i] != np_balanced_test_data_targets[label][i]):\n",
    "            all_true = False\n",
    "    if not all_true:\n",
    "        false_count += 1\n",
    "temp_test_targets = []\n",
    "for label in label_columns:\n",
    "    temp_test_targets.append (np_balanced_test_data_targets[label])\n",
    "hamming_loss_rate = np.sum(np.not_equal(np.transpose(temp_test_targets),\n",
    "                        np.transpose(test_pred_labels)))/float(np.transpose(temp_test_targets).size)\n",
    "print (\"Exact match rate is %0.4f\" % ((test_sample_count-false_count)/test_sample_count))\n",
    "print(\"hamming loss rate is %0.4f\" % (hamming_loss_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.66726893676164, 0.66726893676164, 0.66726893676164, 0.66726893676164, 0.66726893676164, 0.66726893676164, 0.6657400972897846, 0.7000694927032662, 0.6653231410701876, 0.6674079221681724, 0.66726893676164, 0.7021542738012508, 0.7353717859624739, 0.66726893676164, 0.6674079221681724, 0.66726893676164, 0.66726893676164, 0.66726893676164, 0.66726893676164, 0.6674079221681724, 0.66726893676164, 0.66726893676164, 0.66726893676164, 0.66726893676164, 0.6668519805420431, 0.66726893676164, 0.7357887421820708, 0.66726893676164, 0.66726893676164, 0.7000694927032662, 0.66726893676164, 0.66726893676164, 0.66726893676164, 0.66726893676164, 0.66726893676164, 0.66726893676164, 0.66726893676164, 0.66726893676164, 0.66726893676164, 0.66726893676164, 0.66726893676164, 0.66726893676164, 0.66726893676164, 0.7000694927032662, 0.66726893676164, 0.66726893676164, 0.66726893676164, 0.66726893676164, 0.7357887421820708, 0.7353717859624739]\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "2 a\n",
    "'''\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "data_raw = pd.read_csv('Frogs_MFCCs.csv', sep=\",\", header=0)\n",
    "data = data_raw.iloc[:,:25]\n",
    "np_data_features = data.iloc[:,:22].values\n",
    "np.random.seed(42)\n",
    "# monte carlo simulation\n",
    "hamming_distances = []\n",
    "for x in range(50): \n",
    "    #best_CH_index = 0 \n",
    "    best_silhouette_score = -1 \n",
    "    #best_k_CH = 0\n",
    "    best_k_silhouette = 0\n",
    "    for k in range(2, 50, 1):\n",
    "        kmeans = KMeans(n_clusters=k).fit(np_data_features)\n",
    "        labels = kmeans.labels_\n",
    "    #     chIndex = metrics.calinski_harabaz_score(np_data_features, labels)\n",
    "    #     if (chIndex > best_CH_index):\n",
    "    #         best_k = k\n",
    "    #         best_CH_index = chIndex\n",
    "\n",
    "        silhouette_score = metrics.silhouette_score(np_data_features, labels)\n",
    "        if (silhouette_score > best_silhouette_score):\n",
    "            best_k_silhouette = k\n",
    "            best_silhouette_score = silhouette_score\n",
    "    #print (\"best CH index is\",best_CH_index, \"achieved at k =\", best_k)   \n",
    "    #print (\"best silhouette_score is\",best_silhouette_score, \"achieved at k =\", best_k_silhouette)  \n",
    "    \n",
    "    '''\n",
    "    2 b, c\n",
    "    '''\n",
    "    label_columns = [\"Family\",\"Genus\",\"Species\"]\n",
    "    kmeans = KMeans(n_clusters=best_k_silhouette).fit(np_data_features)\n",
    "    labels = kmeans.labels_\n",
    "\n",
    "\n",
    "    majority_triplet = {}\n",
    "    for i in range(len(label_columns)):\n",
    "        # {cluster0 : {label1: frequency(int), label2: frequency(int)...}}\n",
    "        label_frequency = {}\n",
    "        targets = data.iloc[:,22+i:22+i+1].values.tolist()\n",
    "        for j in range(len(targets)): \n",
    "            cluster_number = labels[j]\n",
    "            target = targets[j][0]\n",
    "            if cluster_number not in label_frequency:\n",
    "                label_frequency[cluster_number] = {}\n",
    "            if target not in label_frequency[cluster_number]: \n",
    "                label_frequency[cluster_number][target] = 0 \n",
    "            label_frequency[cluster_number][target] += 1 \n",
    "        #print(label_frequency)\n",
    "        #find the most frequent lable in each cluster and assign that label to the cluster \n",
    "        for key in label_frequency: \n",
    "            if key not in majority_triplet: \n",
    "                majority_triplet[key] = [\"\", \"\" ,\"\"]\n",
    "            majority_name = \"\"\n",
    "            majority_vote = 0\n",
    "            for name in label_frequency[key]: \n",
    "                if label_frequency[key][name] > majority_vote:\n",
    "                    majority_vote = label_frequency[key][name]\n",
    "                    majority_name = name\n",
    "            majority_triplet[key][i] = majority_name\n",
    "    #print (majority_triplet)\n",
    "    predicted_labels = []\n",
    "    for i in range(len(targets)):\n",
    "        cluster_number = labels[i]\n",
    "        predicted_label = majority_triplet[cluster_number]\n",
    "        predicted_labels.append(predicted_label)\n",
    "\n",
    "    np_predicted_labels = np.array(predicted_labels)\n",
    "    np_target_labels = data[label_columns].values\n",
    "    hamming_loss_rate = np.sum(np.not_equal(np.transpose(np_target_labels),\n",
    "                            np.transpose(np_predicted_labels)))/float(np.transpose(np_target_labels).size)\n",
    "    hamming_score = 1 - hamming_loss_rate\n",
    "    hamming_distance = hamming_loss_rate * 3\n",
    "    hamming_distances.append(hamming_distance)\n",
    "    #print(\"hamming loss rate is %0.4f\\nhamming score is %0.4f\\nhamming distance is %0.4f\" \n",
    "   #       % (hamming_loss_rate, hamming_score, hamming_distance))\n",
    "    \n",
    "#end = time.time()\n",
    "#print(\"time taken:\", end - start)\n",
    "#print (hamming_distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average hamming distance is: 0.6753300903405142\n",
      "standard deviation of hamming distance is: 0.01993378297367031\n"
     ]
    }
   ],
   "source": [
    "np_hamming_distances = np.array(hamming_distances)\n",
    "print(\"average hamming distance is:\", np.mean(np_hamming_distances))\n",
    "print(\"standard deviation of hamming distance is:\", np.std(np_hamming_distances))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
